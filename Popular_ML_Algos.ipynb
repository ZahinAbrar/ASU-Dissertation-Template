{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt5FIBSksG5SBeaw1ZbT4L"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "K-means clustering is a popular unsupervised machine learning algorithm used for grouping similar data points into k - clusters. Goal: to partition a given dataset into k (predefined) clusters.\n",
        "\n",
        "The k-means algorithm works by first randomly initializing k cluster centers, one for each cluster. Each data point in the dataset is then assigned to the nearest cluster center based on their distance. The distance metric used is typically Euclidean distance, but other distance measures such as Manhattan distance or cosine similarity can also be used.\n",
        "\n",
        "After all the data points have been assigned to a cluster, the algorithm calculates the new mean for each cluster by taking the average of all the data points assigned to that cluster. These new means become the new cluster centers. The algorithm then repeats the assignment and mean calculation steps until the cluster assignments no longer change or until a maximum number of iterations is reached.\n",
        "\n",
        "The final output of the k-means algorithm is a set of k clusters, where each cluster contains the data points that are most similar to each other based on the distance metric used. The algorithm is commonly used in various fields such as image segmentation, market segmentation, and customer profiling.\n",
        "\n",
        "Initialize:\n",
        "- K: number of clusters\n",
        "- Data: the input dataset\n",
        "- Randomly select K initial centroids\n",
        "\n",
        "Repeat:\n",
        "- Assign each data point to the nearest centroid (based on Euclidean distance)\n",
        "- Calculate the mean of each cluster to update its centroid\n",
        "- Check if the centroids have converged (i.e., they no longer change)\n",
        "\n",
        "Until:\n",
        "- The centroids have converged\n",
        "- The maximum number of iterations has been reached\n",
        "\n",
        "Output:\n",
        "- The final K clusters and their corresponding centroids"
      ],
      "metadata": {
        "id": "3zlB0QJAP1jv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeSZZa2pPokZ"
      },
      "outputs": [],
      "source": [
        "def k_means_cluster(k, points):\n",
        "    # Initialization: choose k centroids (Forgy, Random Partition, etc.)\n",
        "    centroids = [c1, c2, ..., ck]\n",
        "\n",
        "    # Initialize clusters list\n",
        "    clusters = [[] for _ in range(k)]\n",
        "\n",
        "    # Loop until convergence\n",
        "    converged = false\n",
        "    while not converged:\n",
        "        # Clear previous clusters\n",
        "        clusters = [[] for _ in range(k)]\n",
        "\n",
        "        # Assign each point to the \"closest\" centroid\n",
        "        for point in points:\n",
        "            distances_to_each_centroid = [distance(point, centroid) for centroid in centroids]\n",
        "            cluster_assignment = argmin(distances_to_each_centroid)\n",
        "            clusters[cluster_assignment].append(point)\n",
        "\n",
        "        # Calculate new centroids\n",
        "        #   (the standard implementation uses the mean of all points in a\n",
        "        #     cluster to determine the new centroid)\n",
        "        new_centroids = [calculate_centroid(cluster) for cluster in clusters]\n",
        "\n",
        "        converged = (new_centroids == centroids)\n",
        "        centroids = new_centroids\n",
        "\n",
        "        if converged:\n",
        "            return clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write here a working code."
      ],
      "metadata": {
        "id": "_ENYHRGGQYyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization\n",
        "\n",
        "Here are some ways to optimize the k-means clustering algorithm:\n",
        "\n",
        "Random initialization of centroids: Instead of initializing the centroids using the first k data points, we can randomly initialize them to improve the convergence of the algorithm. This can be done by selecting k random data points from the input dataset as the initial centroids.\n",
        "\n",
        "Early stopping: We can stop the k-means algorithm if the cluster assignments and centroids do not change after a certain number of iterations. This helps to avoid unnecessary computation.\n",
        "\n",
        "Vectorization: We can use numpy arrays and vectorized operations to speed up the computation. This avoids the need for loops and makes the code more efficient.\n",
        "\n",
        "Here's an optimized version of the k-means clustering algorithm that implements these optimizations:"
      ],
      "metadata": {
        "id": "lUFFIQL2RmPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic regression:**\n",
        "Logistic regression is a statistical method used for binary classification, which means it is used to predict the probability of an event occurring or not. It is a type of generalized linear model that is used when the dependent variable is binary or categorical.\n",
        "\n",
        "In logistic regression, the dependent variable is binary (i.e., it can take on one of two values, usually 0 or 1), and the independent variables can be either continuous or categorical. The goal of logistic regression is to find the relationship between the independent variables and the dependent variable by estimating the probability of the dependent variable being 1 given the values of the independent variables.\n",
        "\n",
        "The logistic regression model uses a logistic function (also known as the sigmoid function) to map the input values of the independent variables to a value between 0 and 1, which represents the probability of the dependent variable being 1. The logistic function is defined as:"
      ],
      "metadata": {
        "id": "kVPicucLTYBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient and Stochastic Gradient Descent:"
      ],
      "metadata": {
        "id": "m5i9K3d9vfzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(x, y, theta, alpha, num_iters):\n",
        "    m = len(y)\n",
        "    for i in range(num_iters):\n",
        "        h = np.dot(x, theta)\n",
        "        loss = h - y\n",
        "        gradient = np.dot(x.T, loss) / m\n",
        "        theta = theta - alpha * gradient\n",
        "    return theta\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(x, y, theta, alpha, num_iters):\n",
        "    m = len(y)\n",
        "    for i in range(num_iters):\n",
        "        for j in range(m):\n",
        "            h = np.dot(x[j], theta)\n",
        "            loss = h - y[j]\n",
        "            gradient = x[j].T * loss\n",
        "            theta = theta - alpha * gradient\n",
        "    return theta"
      ],
      "metadata": {
        "id": "1B5-9_VUvcfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}